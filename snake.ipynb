{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import curses\n",
    "from curses import KEY_RIGHT, KEY_LEFT, KEY_UP, KEY_DOWN\n",
    "from random import randint\n",
    "import tensorflow as tf\n",
    "from tensorflow import layers\n",
    "import numpy as np\n",
    "import os\n",
    "from tflearn.layers.core import input_data, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "import tflearn\n",
    "\n",
    "# tf.enable_eager_execution()\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_model():\n",
    "    network = input_data(shape=[None, 2, 1], name='input')\n",
    "    network = fully_connected(network, 1, activation='linear')\n",
    "    network = regression(network, optimizer='adam', learning_rate=1e-2, loss='mean_square', name='target')\n",
    "    model = tflearn.DNN(network, tensorboard_dir='log')\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.append([np.array([1, 256]), np.array(1)])\n",
    "training_data.append([np.array([1, 256]), np.array(1)])\n",
    "training_data.append([np.array([0, 256]), np.array(0)])\n",
    "training_data.append([np.array([0, 256]), np.array(0)])\n",
    "training_data.append([np.array([0, 256]), np.array(0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(1), array(1), array(0), array(0), array(0)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list((i[1] for i in training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Run id: FP8MGI\n",
      "Log directory: log/\n",
      "---------------------------------\n",
      "Training samples: 5\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 1  | time: 0.049s\n",
      "| Adam | epoch: 001 | loss: 0.00000 -- iter: 5/5\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32m34.35497\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 002 | loss: 34.35497 -- iter: 5/5\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32m16.95657\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 003 | loss: 16.95657 -- iter: 5/5\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32m5.17932\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 004 | loss: 5.17932 -- iter: 5/5\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32m3.44247\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 005 | loss: 3.44247 -- iter: 5/5\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32m5.85746\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 006 | loss: 5.85746 -- iter: 5/5\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32m7.27341\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 007 | loss: 7.27341 -- iter: 5/5\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32m6.61515\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 008 | loss: 6.61515 -- iter: 5/5\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32m4.59730\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 009 | loss: 4.59730 -- iter: 5/5\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32m2.52559\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 010 | loss: 2.52559 -- iter: 5/5\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "x = np.array([i[0] for i in training_data]).reshape(-1, 2, 1)\n",
    "y = np.array([i[1] for i in training_data]).reshape(-1, 1)\n",
    "model = training_model()\n",
    "model.fit(x, y, n_epoch=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.2534963]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array([0, 256]).reshape(-1, 2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
